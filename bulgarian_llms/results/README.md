### SmolLM2-135M (batch size 128, 3 epochs)

All Tensorboard metrics: https://huggingface.co/petkopetkov/SmolLM2-135M-bg/tensorboard

<div style="display: flex; justify-content: space-around; align-items: center;">
  <div>
    <img src="./images/SmolLM2-135M_plots/train_loss.svg" alt="Train Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Train loss</b></div>
  </div>
  <div>
    <img src="./images/SmolLM2-135M_plots/eval_loss.svg" alt="Eval Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Eval loss</b></div>
  </div>
</div>

### Llama3.2-1B (batch size 64, 3 epochs)

All Tensorboard metrics: https://huggingface.co/petkopetkov/Llama3.2-1B-bg/tensorboard

<div style="display: flex; justify-content: space-around; align-items: center;">
  <div>
    <img src="./images/Llama3.2-1B_plots/train_loss.svg" alt="Train Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Train loss</b></div>
  </div>
  <div>
    <img src="./images/Llama3.2-1B_plots/eval_loss.svg" alt="Eval Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Eval loss</b></div>
  </div>
</div>

### Llama3.2-1B-Instruct (batch size 64, 3 epochs)

All Tensorboard metrics: https://huggingface.co/petkopetkov/Llama3.2-1B-Instruct-bg/tensorboard

<div style="display: flex; justify-content: space-around; align-items: center;">
  <div>
    <img src="./images/Llama3.2-1B-Instruct_plots/train_loss.svg" alt="Train Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Train loss</b></div>
  </div>
  <div>
    <img src="./images/Llama3.2-1B-Instruct_plots/eval_loss.svg" alt="Eval Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Eval loss</b></div>
  </div>
</div>

### Llama3.2-1B (custom tokenizer, batch size 64, 3 epochs)

All Tensorboard metrics: https://huggingface.co/petkopetkov/Llama3.2-1B-Instruct-bg-tokenizer/tensorboard

<div style="display: flex; justify-content: space-around; align-items: center;">
  <div>
    <img src="./images/Llama3.2-1B-tokenizer_plots/train_loss.svg" alt="Train Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Train loss</b></div>
  </div>
  <div>
    <img src="./images/Llama3.2-1B-tokenizer_plots/eval_loss.svg" alt="Eval Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Eval loss</b></div>
  </div>
</div>

### Gemma-2-2B (batch size 64, 3 epochs)

All Tensorboard metrics: https://huggingface.co/petkopetkov/gemma-2-2b-bg/tensorboard

<div style="display: flex; justify-content: space-around; align-items: center;">
  <div>
    <img src="./images/gemma-2-2b_plots/train_loss.svg" alt="Train Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Train loss</b></div>
  </div>
  <div>
    <img src="./images/gemma-2-2b_plots/eval_loss.svg" alt="Eval Loss" style="width: 100%;">
    <div style="text-align: center;"><b>Eval loss</b></div>
  </div>
</div>