{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-21 21:42:55--  https://chitanka.info/text/4618-frankenshtajn.txt.zip\n",
      "Resolving chitanka.info (chitanka.info)... 2a06:98c1:3121::2, 2a06:98c1:3120::2, 188.114.97.2, ...\n",
      "Connecting to chitanka.info (chitanka.info)|2a06:98c1:3121::2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://m3.chitanka.info/text/4618-frankenshtajn.txt.zip?filename= [following]\n",
      "--2024-09-21 21:42:56--  https://m3.chitanka.info/text/4618-frankenshtajn.txt.zip?filename=\n",
      "Resolving m3.chitanka.info (m3.chitanka.info)... 2a06:98c1:3120::2, 2a06:98c1:3121::2, 188.114.96.2, ...\n",
      "Connecting to m3.chitanka.info (m3.chitanka.info)|2a06:98c1:3120::2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cache/dl/Mary-Shelley_-_Frankenshtajn_-_4618.txt.zip [following]\n",
      "--2024-09-21 21:42:56--  https://m3.chitanka.info/cache/dl/Mary-Shelley_-_Frankenshtajn_-_4618.txt.zip\n",
      "Reusing existing connection to [m3.chitanka.info]:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 199044 (194K) [application/zip]\n",
      "Saving to: ‘4618-frankenshtajn.txt.zip’\n",
      "\n",
      "4618-frankenshtajn. 100%[===================>] 194.38K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-09-21 21:42:56 (6.59 MB/s) - ‘4618-frankenshtajn.txt.zip’ saved [199044/199044]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "!wget https://chitanka.info/text/4618-frankenshtajn.txt.zip\n",
    "\n",
    "path = \"4618-frankenshtajn.txt.zip\"\n",
    "\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "    \n",
    "!mv \"Mary-Shelley -  - . Frankenshtajn - 4618.txt\" \"dataset.txt\"\n",
    "\n",
    "!rm $path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !$()*,-./0123456789:;=?DIMNVX[]_abcdefghijkmnoprstuvx«»АБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЮЯабвгдежзийклмнопрстуфхцчшщъьюя–—“„…\\ufeff'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars = set(text)\n",
    "sorted_chars = sorted(unique_chars)\n",
    "sorted_chars\n",
    "\"\".join(sorted_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = { c: i for i, c in enumerate(sorted_chars) }\n",
    "\n",
    "def encode(text: str):\n",
    "    return [encoding[c] for c in text]\n",
    "\n",
    "def test_encode():\n",
    "    test_text = \"франкейщайн!\"\n",
    "    test_encoding = encode(test_text)\n",
    "    assert test_encoding[0] == encoding[test_text[0]]\n",
    "    assert test_encoding[1] == encoding[test_text[1]]\n",
    "    \n",
    "# test_encode()\n",
    "\n",
    "decoding = { i: c for i, c in enumerate(sorted_chars) }\n",
    "\n",
    "test_text = \"франкейщайн!\"\n",
    "test_encoding = encode(test_text)\n",
    "\n",
    "def decode(arr):\n",
    "    return \"\".join([decoding[t] for t in arr])\n",
    "\n",
    "def test_decode():\n",
    "    test_text = \"франкейщайн!\"\n",
    "    assert decode(encode(test_text)) == test_text\n",
    "    \n",
    "# test_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120,   0,  69,  ...,  13,   1,   1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120,   0,  69,  ..., 102,  95,  99])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size = round(len(data) * 0.9)\n",
    "\n",
    "train_data = data[:train_data_size]\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([103,  99,   2,  ...,  13,   1,   1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = data[train_data_size:]\n",
    "\n",
    "val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120,   0,  69,  90, 101,  93,   2,  81,  90])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120,   0,  69,  90, 101,  93,   2,  81])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = train_data[:context_length]\n",
    "\n",
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff\\tМери Ш'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model_input.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = train_data[1:context_length+1]\n",
    "\n",
    "model_output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'е'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model_output.numpy().tolist())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 99,  87,  85,   2, 108, 104,  89,  99],\n",
       "         [ 98,  85,   2,  97,  99, 114,   2,  87],\n",
       "         [ 98,  85,  89,   2,  98,  85,  94,   9],\n",
       "         [ 90,   2, 102,  93,   2,  93,   2, 107]]),\n",
       " tensor([[ 87,  85,   2, 108, 104,  89,  99,  87],\n",
       "         [ 85,   2,  97,  99, 114,   2,  87, 111],\n",
       "         [ 85,  89,   2,  98,  85,  94,   9, 110],\n",
       "         [  2, 102,  93,   2,  93,   2, 107, 114]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4 # sequences in parallel\n",
    "context_length = 8 # chars in a sequence\n",
    "\n",
    "def get_batch(split: str):\n",
    "    batch_data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(batch_data) - context_length, (batch_size,))\n",
    "    \n",
    "    x = torch.stack([batch_data[i:i+context_length] for i in ix])\n",
    "        \n",
    "    y = torch.stack([batch_data[i+1:i+context_length+1] for i in ix])\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "xb, yb # xb is input, yb is expected output (logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
